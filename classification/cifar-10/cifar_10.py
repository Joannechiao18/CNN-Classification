# -*- coding: utf-8 -*-
"""cifar-10.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1i227K9jtgppa9Dy3LnzQwCb92PuTkn5-
"""

import numpy as np 
import pandas as pd 
import keras
from keras.datasets import cifar10
from keras.layers import Activation, Conv2D, Dense, Dropout, Flatten, MaxPooling2D, BatchNormalization
from keras.models import Sequential, load_model
from keras.utils.np_utils import to_categorical
from keras.preprocessing.image import ImageDataGenerator
from keras.callbacks import LearningRateScheduler
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
from keras.models import load_model

(X_train, y_train), (X_test, y_test) = cifar10.load_data()

def lr_decay(epoch):
    lr = 0.001
    
    if epoch > 30: 
        for e in range(epoch - 30):
            lr*=0.98
            
    return lr

validation_rate = 0.2
IMAGE_SIZE = 32            
BATCH_SIZE = 700

fig, img = plt.subplots(ncols=7, nrows=3, figsize=(17, 8))

labels = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']

index=0
#print(y_train[index])
for i in range(3):
  for j in range(7):
    img[i,j].set_title(labels[y_train[index][0]])
    img[i,j].imshow(X_train[index])
    img[i,j].get_xaxis().set_visible(False)
    img[i,j].get_yaxis().set_visible(False)
    index += 1
plt.show()

X_test  = X_test / 255.0   

y_train = to_categorical(y_train, num_classes=10)
y_test  = to_categorical(y_test, num_classes=10)

X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)

train_datagen = ImageDataGenerator(     
    rescale=1.0 / 255,       
    rotation_range=20,       
    #width_shift_range=0.2,   
    #height_shift_range=0.2,  
    #shear_range=0.2,         
    #zoom_range=0.2,          
)

train_generator = train_datagen.flow(
    X_train,
    y_train,
    shuffle = True,
    batch_size=BATCH_SIZE,
)

validation_datagen = ImageDataGenerator(rescale=1.0 / 255,)

validation_generator = validation_datagen.flow(
    X_val,
    y_val,
    batch_size=BATCH_SIZE,
)

model = Sequential()

model.add(Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(32, 32, 3)))
model.add(BatchNormalization())
model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))
model.add(BatchNormalization())
model.add(MaxPooling2D((2, 2)))
model.add(Dropout(0.3))
 
model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))
model.add(BatchNormalization())
model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))
model.add(BatchNormalization())
model.add(MaxPooling2D((2, 2)))
model.add(Dropout(0.4))
 
model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))
model.add(BatchNormalization())
model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))
model.add(BatchNormalization())
model.add(MaxPooling2D((2, 2)))
model.add(Dropout(0.4))
 
model.add(Flatten())
model.add(Dense(128, activation='relu'))
model.add(BatchNormalization())
model.add(Dropout(0.5))
model.add(Dense(10, activation='softmax'))

model.compile(
    loss='categorical_crossentropy',
    optimizer='adam',                
    metrics=['accuracy']
)

lr_change = LearningRateScheduler(lr_decay)

#history = model.fit(X_train, y_train, epochs=100, batch_size=BATCH_SIZE, validation_data=(X_val, y_val), verbose=1, callbacks=[lr_change])
history=model.fit_generator(
    train_generator,                      
    epochs=100,                         
    steps_per_epoch=X_train.shape[0] / BATCH_SIZE,      
    validation_data=validation_generator, 
    validation_steps=X_val.shape[0] / BATCH_SIZE,
    verbose=1,
    callbacks=[lr_change],
)

plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Accuracy')
plt.xlabel('epoch')
plt.ylabel('accuracy')
plt.ylim([0.00, 1.00])
plt.legend(['acc', 'val_acc'], loc='lower right')
plt.show()

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Loss')
plt.xlabel('epoch')
plt.ylabel('loss')
plt.legend(['loss', 'val_loss'])
plt.show()

scores = model.evaluate(X_test, y_test, verbose=1)

model.save("cifar_10_model.h5")

model = keras.models.load_model("cifar_10_model.h5")

prediction=model.predict_classes(X_test)

label_dict={0:"airplane",1:"automobile",2:"bird",3:"cat",4:"deer",
            5:"dog",6:"frog",7:"horse",8:"ship",9:"truck"}

def plot_images_labels_prediction(images, labels, prediction, idx, num):
    fig = plt.gcf()
    fig.set_size_inches(20, 20)  #一個圖片大小
    for i in range(0, num):
        img=plt.subplot(12,12, 1+i)  #6x6表格
        img.imshow(images[idx])

        buf=to_categorical(prediction[i], 10)

        if len(prediction)>0:
          title=label_dict[prediction[i]]
          if (buf == y_test[i]).all():
            img.set_title(title,fontsize=15,color='black') 
          else:
            img.set_title(title,fontsize=15,color='red') 
            
        img.set_xticks([]);img.set_yticks([])        
        idx+=1 
    plt.show()

plot_images_labels_prediction(X_test, y_test, prediction, 0, 100)
